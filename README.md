# Reverse Image Search Using Image Captioning

This repository contains the Jupyter notebook for the research project titled "Reverse Image Search Using Image Captioning". The project integrates advanced deep learning techniques, specifically a vision transformer encoder-decoder model, with reverse image search functionalities to enhance the precision and context-awareness of image retrieval.

## Abstract
Reverse image search systems traditionally rely on direct image feature comparisons, which can limit their ability to accurately interpret and retrieve images based on context or abstract content descriptions. This study introduces a novel approach that focuses on leveraging the descriptive power of image captions, specifically the last two words, as search queries. Preliminary results indicate a significant improvement in retrieving fashion-related images, underscoring the potential of this method for more accurate and context-aware reverse image searches.

## Dataset
The model was trained using the Fashion Product Images Dataset available on Kaggle. More information about the dataset can be found at:
https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset

## Notebook Contents
- Data Preprocessing
- Model Architecture
- Training Procedures
- Validation and Performance Metrics
- Example Outputs and Visualizations


## Installation
To set up the project environment to run the notebook, follow these steps:

```bash
https://github.com/pranshavpatel/reverse-image-search-using-image-captioning.git
cd reverse-image-search-using-image-captioning
jupyter-notebook
